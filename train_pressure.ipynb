{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "\n",
    "from preprocessing import get_cv_val_ids, get_data_splits\n",
    "from models import BlitzData, BlitzFrameData, BlitzLSTM, PressureFrameTransformer\n",
    "from utils import combine_batch, combine_batch2\n",
    "from training import train_epoch, validate_epoch, train_epoch2, validate_epoch2, get_lstm_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.deterministic = True\n",
    "torch.manual_seed(2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/feats.csv\")\n",
    "\n",
    "data[\"y\"] = data[\"y\"].fillna(0)\n",
    "data[\"y_pressure\"] = data[\"y_pressure\"].fillna(0)\n",
    "data[\"acc\"] = data[\"acc\"].fillna(0)\n",
    "data[\"blitz_prob\"] = np.where(\n",
    "    (data[\"pass_rusher\"] == 1) & (data[\"y\"] == -1),\n",
    "    1., data[\"blitz_prob\"]\n",
    ")\n",
    "data[\"blitz_prob\"] = data[\"blitz_prob\"].fillna(0)\n",
    "data[\"index\"] = data.groupby([\"game_id\", \"play_id\", \"player_id\"]).cumcount()\n",
    "\n",
    "# at least one blitzer or rush at least 5 \n",
    "filt = data.groupby([\"game_id\", \"play_id\"])[\"y\"].transform(lambda x: np.any(x == 1))\n",
    "filt = filt | data.groupby([\"game_id\", \"play_id\"])[\"pass_rusher\"].transform(lambda x: x.mean() > 4/22)\n",
    "data = data[filt].reset_index(drop=True)\n",
    "data = data.dropna(subset=[\"rel_x_lag\"])\n",
    "\n",
    "play_data = pd.read_csv(\"data/play_feats.csv\")\n",
    "play_data = play_data.set_index([\"game_id\", \"play_id\"])\n",
    "play_data[\"is_man\"] = play_data[\"is_man\"].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_data_dict = {}\n",
    "for key, df in play_data.groupby(play_data.index):\n",
    "    play_data_dict[key] = df.iloc[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ids = get_cv_val_ids(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_preds = []\n",
    "all_preds = []\n",
    "#for i in range(len(val_ids)):\n",
    "for i in range(len(val_ids)):\n",
    "\n",
    "    if i != 7:\n",
    "        continue\n",
    "\n",
    "    print(f\"Training with week {i + 1} as validation set.\\n\")\n",
    "\n",
    "    data_lstm = data.loc[data[\"y\"] == 1].copy()\n",
    "    data_lstm = data_lstm.loc[data[\"tts\"] < 100]\n",
    "    data_lstm[\"position_id\"] = data_lstm[\"position_id\"].apply(\n",
    "        lambda x: np.select(\n",
    "            [x == 6, x == 7, x == 9, x == 11, x == 14],\n",
    "            [0, 1, 2, 3, 4]\n",
    "        )\n",
    "    )\n",
    "    train_df = data_lstm.loc[~data_lstm.index.isin(val_ids[i])]\n",
    "    val_df = data_lstm.loc[data_lstm.index.isin(val_ids[i])]\n",
    "\n",
    "    # feature sequences by player for lstm (n_frames x n_features) \n",
    "    feats = [\"rel_x\", \"rel_y\", \"speed_x\", \"speed_y\", \"acc\", \n",
    "             \"blitz_prob_norm\", \"tts\", \"position_id\"]\n",
    "    train = []\n",
    "    for key, df in train_df.groupby([\"game_id\", \"play_id\", \"player_id\"]):\n",
    "        y = df[\"play_pressure\"].values \n",
    "        df = df.drop(columns=\"y_pressure\")\n",
    "        X = df[feats].values\n",
    "        train.append((key, X, y))\n",
    "    val = []\n",
    "    for key, df in val_df.groupby([\"game_id\", \"play_id\", \"player_id\"]):\n",
    "        y = df[\"play_pressure\"].values \n",
    "        df = df.drop(columns=\"y_pressure\")\n",
    "        X = df[feats].values\n",
    "        val.append((key, X, y))\n",
    "\n",
    "    train_data = BlitzData(train)\n",
    "    train_loader = DataLoader(train_data, batch_size=64, collate_fn=combine_batch, shuffle=True)\n",
    "    val_data = BlitzData(val)\n",
    "    val_loader = DataLoader(val_data, batch_size=64, collate_fn=combine_batch)\n",
    "\n",
    "    input_dim = train[0][1].shape[1]\n",
    "    model = BlitzLSTM(input_dim, hidden_dim=16, output_dim=1, num_lstm_layers=1)\n",
    "    optimizer = AdamW(model.parameters(), lr=2e-4, weight_decay=0.01)\n",
    "    loss_fn = nn.BCELoss()\n",
    "\n",
    "    best_loss = 1.\n",
    "    best_epoch = 0\n",
    "    epoch = 0 \n",
    "    while epoch - best_epoch < 5:\n",
    "\n",
    "        train_loss = train_epoch(train_loader, model, optimizer, loss_fn, final_output=True)\n",
    "        val_loss, val_preds = validate_epoch(val_loader, model, loss_fn, final_output=True)\n",
    "\n",
    "        print(f\"Epoch {epoch}:\\n\")\n",
    "        print(f\"Train loss: {np.round(train_loss, 4)}, Val loss: {np.round(val_loss, 4)}\")\n",
    "        \n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            best_epoch = epoch\n",
    "            best_preds = val_preds.copy()\n",
    "        \n",
    "        epoch += 1\n",
    "\n",
    "    # save lstm preds \n",
    "    val_preds_df = pd.DataFrame()\n",
    "    for key, arr in val_preds.items():\n",
    "        df = pd.DataFrame(arr, columns=[\"pred\"])\n",
    "        df[\"game_id\"] = key[0]\n",
    "        df[\"play_id\"] = key[1]\n",
    "        df[\"player_id\"] = key[2]\n",
    "        val_preds_df = pd.concat([val_preds_df, df])\n",
    "    val_preds_df = val_preds_df[[\"game_id\", \"play_id\", \"player_id\", \"pred\"]]\n",
    "    lstm_preds.append(val_preds_df)\n",
    "\n",
    "    all_data = BlitzData(train + val)\n",
    "    all_data_loader = DataLoader(all_data, batch_size=128, collate_fn=combine_batch)\n",
    "    all_df = get_lstm_output(model, all_data_loader)\n",
    "\n",
    "    # add lstm output as feature for transformer model \n",
    "    if \"lstm0\" in data.columns:\n",
    "        data = data.drop(columns=\"lstm0\")\n",
    "    data = data.merge(all_df, on=[\"game_id\", \"play_id\", \"player_id\", \"index\"], how=\"left\")\n",
    "    data[\"lstm0\"] = np.where(\n",
    "        data[\"y\"] == -1, 0.45, data[\"lstm0\"]\n",
    "    )\n",
    "    data[\"lstm0\"] = data[\"lstm0\"].fillna(0.)\n",
    "\n",
    "    feats = [\"rel_x\", \"rel_y\", \"rel_x_lag\", \"rel_y_lag\", \"speed_x\", \"speed_y\", \n",
    "             \"acc\", \"pass_rusher\", \"lstm0\", \"tts\", \"position_id\"]\n",
    "    train, val = get_data_splits(data, \n",
    "                                 play_data_dict, \n",
    "                                 val_ids[i], \n",
    "                                 feats=feats,\n",
    "                                 label=\"y_pressure\",\n",
    "                                 mirror_train=True)\n",
    "    train = [x for x in train if x[1][0, -2] < 100]\n",
    "    val = [x for x in val if x[1][0, -2] < 100]\n",
    "\n",
    "    train_data = BlitzFrameData(train)\n",
    "    val_data = BlitzFrameData(val)\n",
    "    train_loader = DataLoader(train_data, batch_size=64, shuffle=True, collate_fn=combine_batch2)\n",
    "    val_loader = DataLoader(val_data, batch_size=64, collate_fn=combine_batch2)\n",
    "\n",
    "    input_dim = train[0][1].shape[1] - 2\n",
    "    z_input_dim = len(train[0][2])\n",
    "    device = torch.device(\"cpu\")\n",
    "    model = PressureFrameTransformer(input_dim, z_input_dim, 32, 1, 1)\n",
    "    optimizer = AdamW(model.parameters(), lr=1e-4, weight_decay=0.03)\n",
    "    loss_fn = nn.BCELoss()\n",
    "\n",
    "    best_loss = 1.\n",
    "    best_epoch = 0\n",
    "    epoch = 0 \n",
    "    while epoch - best_epoch < 7:\n",
    "\n",
    "        train_loss, train_preds = train_epoch2(train_loader, model, optimizer, loss_fn, device, pool=True)\n",
    "        val_loss, val_preds = validate_epoch2(val_loader, model, loss_fn, device, pool=True)\n",
    "\n",
    "        print(f\"Epoch {epoch}:\\n\")\n",
    "        print(f\"Train loss: {np.round(train_loss, 4)}, Val loss: {np.round(val_loss, 4)}\")\n",
    "        \n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            best_epoch = epoch\n",
    "            best_preds = val_preds.copy()\n",
    "            best_train_preds = train_preds.copy()\n",
    "        \n",
    "        epoch += 1\n",
    "\n",
    "    keys = []\n",
    "    vals = []\n",
    "    for k, v in val_preds.items():\n",
    "        keys.append(k)\n",
    "        vals.append(v)\n",
    "    df = pd.DataFrame(vals, \n",
    "                      columns=[\"pred\"],\n",
    "                      index=pd.MultiIndex.from_tuples(keys, names=[\"game_id\", \"play_id\", \"frame_id\"]))\n",
    "    df = df.reset_index()\n",
    "    all_preds.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds_df = pd.concat(all_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds_df.to_csv(\"data/cv_pressure_preds.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bdb-25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
